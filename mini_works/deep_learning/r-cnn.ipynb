{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8008269,"sourceType":"datasetVersion","datasetId":3775672,"isSourceIdPinned":false}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"s076923/pytorch-transformer\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nfrom PIL import Image\nfrom pycocotools.coco import COCO\nfrom torch.utils.data import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:16.252553Z","iopub.execute_input":"2025-07-07T03:29:16.252833Z","iopub.status.idle":"2025-07-07T03:29:20.482710Z","shell.execute_reply.started":"2025-07-07T03:29:16.252760Z","shell.execute_reply":"2025-07-07T03:29:20.481950Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## 데이터 클래스 생성","metadata":{}},{"cell_type":"code","source":"class COCODataset(Dataset):\n    def __init__(self, root, train, transform=None):\n        #초기화\n        super().__init__()\n        directory = \"train\" if train else \"val\"\n        annotations = os.path.join(root, \"annotations\", f\"{directory}_annotations.json\")\n        self.coco = COCO(annotations)\n        self.image_path = os.path.join(root, directory)\n        self.transform = transform \n        self.categories = self.__get_categories()\n        self.data = self.__load_data()\n        \n           \n    def __get_categories(self):\n        #coco 데이터셋 기반으로 라벨 지정\n        categories = {0 : 'background'}\n        for category in self.coco.cats.values():\n            categories[category['id']] = category['name']\n        return categories\n    \n    def __load_data(self):\n        data = []\n        for _id in self.coco.imgs:\n            file_name = self.coco.loadImgs(_id)[0]['file_name']\n            image_path = os.path.join(self.image_path, file_name)\n            image = Image.open(image_path).convert(\"RGB\")\n\n            boxes = []\n            labels = []\n            anns = self.coco.loadAnns(self.coco.getAnnIds(_id))\n\n            for ann in anns:\n                x, y, w, h = ann['bbox']\n                boxes.append([x, y, x+w, y+h])\n                labels.append(ann['category_id'])\n            target = {\n                'image_id' : torch.LongTensor([_id]),\n                'boxes' : torch.FloatTensor(boxes),\n                'labels' : torch.LongTensor(labels)\n            }\n            data.append([image, target])\n        return data\n       \n    \n    def __getitem__(self, index):\n        image, target = self.data[index]\n        if self.transform:\n            image =self.transform(image)\n        return image, target\n        \n    def __len__(self):\n        return len(self.data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:20.483569Z","iopub.execute_input":"2025-07-07T03:29:20.483966Z","iopub.status.idle":"2025-07-07T03:29:20.492637Z","shell.execute_reply.started":"2025-07-07T03:29:20.483945Z","shell.execute_reply":"2025-07-07T03:29:20.491764Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from torchvision import transforms\nfrom torch.utils.data import DataLoader\n\ndef collator(batch):\n    return tuple(zip(*batch))\n    #사진 한 장에 여러 라벨이 들어있는 경우에 첫 번째 라벨만 들어갈 수 있도록 한다.\n\ntransform = transforms.Compose([\n    transforms.PILToTensor(),\n    transforms.ConvertImageDtype(dtype = torch.float)\n])\nroot = '/kaggle/input/pytorch-transformer/datasets/coco'\ntrain_dataset = COCODataset(root, train = True, transform = transform)\ntrain_dataloader = DataLoader(train_dataset, batch_size = 4, shuffle = True, drop_last = True,\n          collate_fn = collator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:20.495297Z","iopub.execute_input":"2025-07-07T03:29:20.495759Z","iopub.status.idle":"2025-07-07T03:29:45.652899Z","shell.execute_reply.started":"2025-07-07T03:29:20.495730Z","shell.execute_reply":"2025-07-07T03:29:45.652329Z"}},"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=0.09s)\ncreating index...\nindex created!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"train_dataset = COCODataset(root, train = False, transform = transform)\ntrain_dataloader = DataLoader(train_dataset, batch_size = 4, shuffle = True, drop_last = True,\n          collate_fn = collator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:45.653596Z","iopub.execute_input":"2025-07-07T03:29:45.653881Z","iopub.status.idle":"2025-07-07T03:29:47.180158Z","shell.execute_reply.started":"2025-07-07T03:29:45.653856Z","shell.execute_reply":"2025-07-07T03:29:47.179624Z"}},"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=0.01s)\ncreating index...\nindex created!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from torchvision import models\nfrom torchvision import ops\nfrom torchvision.models.detection import rpn, FasterRCNN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:47.181125Z","iopub.execute_input":"2025-07-07T03:29:47.181413Z","iopub.status.idle":"2025-07-07T03:29:47.185046Z","shell.execute_reply.started":"2025-07-07T03:29:47.181389Z","shell.execute_reply":"2025-07-07T03:29:47.184295Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 백본으로 VGG16 사용","metadata":{}},{"cell_type":"code","source":"backbone = models.vgg16(weights=\"VGG16_Weights.IMAGENET1K_V1\").features\nbackbone.out_channels = 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:47.185750Z","iopub.execute_input":"2025-07-07T03:29:47.186032Z","iopub.status.idle":"2025-07-07T03:29:51.100024Z","shell.execute_reply.started":"2025-07-07T03:29:47.186013Z","shell.execute_reply":"2025-07-07T03:29:51.099455Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 232MB/s] \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"anchor_generator = rpn.AnchorGenerator(\n    sizes = ((32, 64, 128, 256, 512),),\n    aspect_ratios = ((0.5, 1.0, 2.0))\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:51.100730Z","iopub.execute_input":"2025-07-07T03:29:51.100921Z","iopub.status.idle":"2025-07-07T03:29:51.116654Z","shell.execute_reply.started":"2025-07-07T03:29:51.100906Z","shell.execute_reply":"2025-07-07T03:29:51.116117Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"roi_pooler = ops.MultiScaleRoIAlign(\n    featmap_names = [\"0\"],\n    output_size=(7,7),\n    sampling_ratio = 2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:51.117347Z","iopub.execute_input":"2025-07-07T03:29:51.117562Z","iopub.status.idle":"2025-07-07T03:29:51.165352Z","shell.execute_reply.started":"2025-07-07T03:29:51.117545Z","shell.execute_reply":"2025-07-07T03:29:51.164614Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\nelse:\n    DEVICE = torch.device('cpu')\nprint('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:51.167572Z","iopub.execute_input":"2025-07-07T03:29:51.167791Z","iopub.status.idle":"2025-07-07T03:29:51.237965Z","shell.execute_reply.started":"2025-07-07T03:29:51.167773Z","shell.execute_reply":"2025-07-07T03:29:51.237248Z"}},"outputs":[{"name":"stdout","text":"Using PyTorch version: 2.6.0+cu124  Device: cuda\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model = FasterRCNN(\n    backbone=backbone, \n    num_classes = 3,\n    rpn_anchor_generator = anchor_generator,\n    box_roi_pool  = roi_pooler\n).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:51.238614Z","iopub.execute_input":"2025-07-07T03:29:51.238831Z","iopub.status.idle":"2025-07-07T03:29:51.624788Z","shell.execute_reply.started":"2025-07-07T03:29:51.238813Z","shell.execute_reply":"2025-07-07T03:29:51.624220Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from torch import optim\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\nlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:51.625416Z","iopub.execute_input":"2025-07-07T03:29:51.625656Z","iopub.status.idle":"2025-07-07T03:29:51.630211Z","shell.execute_reply.started":"2025-07-07T03:29:51.625638Z","shell.execute_reply":"2025-07-07T03:29:51.629532Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"\nfor epoch in range(5):\n    cost = 0.0\n    for idx, (images, targets)  in enumerate(train_dataloader):\n        #image = image.to(device)\n        images = list(image.to(DEVICE) for image in images)\n        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n        loss_dict = model(images, targets)\n        losses = sum([loss for loss in loss_dict.values()])\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n        cost += losses \n    lr_scheduler.step()\n    cost = cost / len(train_dataloader)\n    print(f\"Epoch : {epoch + 1:4d}, Cost : {cost:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:29:51.631031Z","iopub.execute_input":"2025-07-07T03:29:51.631565Z"}},"outputs":[{"name":"stdout","text":"Epoch :    1, Cost : 1.164\nEpoch :    2, Cost : 0.708\nEpoch :    3, Cost : 0.386\nEpoch :    4, Cost : 0.342\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom torchvision.transforms.functional import to_pil_image\n\n\ndef draw_bbox(ax, box, text, color):\n    ax.add_patch(\n        plt.Rectangle(\n            xy=(box[0], box[1]),\n            width=box[2] - box[0],\n            height=box[3] - box[1],\n            fill=False,\n            edgecolor=color,\n            linewidth=2,\n        )\n    )\n    ax.annotate(\n        text=text,\n        xy=(box[0] - 5, box[1] - 5),\n        color=color,\n        weight=\"bold\",\n        fontsize=13,\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}